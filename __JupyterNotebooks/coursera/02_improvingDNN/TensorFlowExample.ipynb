{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellType": "FrontMatter"
   },
   "source": [
    "---\n",
    "title: Assignment 00 - Tensor Flow Example \n",
    "tags: [jupyter]\n",
    "keywords: course, coursera, tuningHyperParam\n",
    "summary: This was a code in the lecture notes\n",
    "sidebar: coursera_sidebar\n",
    "permalink: __AutoGenThis__\n",
    "notebookfilename:  __AutoGenThis__\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\envs\\mlPlaygroundPy36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\HP\\Anaconda2\\envs\\mlPlaygroundPy36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\HP\\Anaconda2\\envs\\mlPlaygroundPy36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\HP\\Anaconda2\\envs\\mlPlaygroundPy36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\HP\\Anaconda2\\envs\\mlPlaygroundPy36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\HP\\Anaconda2\\envs\\mlPlaygroundPy36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "---\n",
    "title: Assignment 00 - Tensor Flow Example Changing Variables\n",
    "tags: [jupyter]\n",
    "keywords: course, coursera, tuningHyperParam\n",
    "summary: This was a code in the lecture notes\n",
    "sidebar: coursera_sidebar\n",
    "permalink: __AutoGenThis__\n",
    "notebookfilename:  __AutoGenThis__\n",
    "---import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to minimize the cost function\n",
    "\n",
    "$$J(w) = w^2 - 10w +25$$\n",
    "\n",
    "Notice that this can be reduced to the function $$(w-5)^2$$ with a minima of `w=5`\n",
    "\n",
    "Lets use tensorflow to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable\n",
    "w = tf.Variable(0,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be written as this - cost = w**2 - 10*w + 25\n",
    "#cost = tf.add(tf.add(w**2, tf.multiply(-10.0, w)), 25.0)   \n",
    "\n",
    "# Alternative to the above\n",
    "cost = w**2 - 10*w +25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with gradient decent\n",
    "learningRate = 0.01\n",
    "train = tf.train.GradientDescentOptimizer(learningRate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following few lines are quite idiomatic\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# this starts a TF session\n",
    "session = tf.Session()\n",
    "session.run(init) # init global variables\n",
    "session.run(w)    # Runs the definition of w, if you print this it will print zero\n",
    "session.run(train) # this runs one set of grad desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W after one iteration: 0.099999994\n"
     ]
    }
   ],
   "source": [
    "print(\"W after one iteration:\", session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now W was updated and it found this.  We need to run this multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W after 1000 iterations: 4.9999886\n"
     ]
    }
   ],
   "source": [
    "numIter = 1000  \n",
    "for i in range(numIter):\n",
    "  session.run(train)\n",
    "\n",
    "print(\"W after 1000 iterations:\", session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimum number is 5 and we got really really close.\n",
    "\n",
    "> And notice that all we had to do was define a cost function using these add and multiply and so on functions.  And TensorFlow knows automatically how to take derivatives with respect to the add and multiply as was other functions.  Which is why you only had to implement basically four prop and it can figure out how to do the back problem or the grading computation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlPlaygroundPy36",
   "language": "python",
   "name": "mlplaygroundpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
